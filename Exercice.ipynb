{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Contexte et objectifs du projet :\n",
    "Ce projet vise à développer un modèle de machine learning capable de prédire l’âge de l’auteur d’un texte (adolescent ou adulte) à partir d’un dataset contenant des textes étiquetés. L'objectif principal est de démontrer comment les techniques de machine learning peuvent être appliquées à des données textuelles pour résoudre un problème de classification."
   ],
   "id": "50d9df6ba7fe9279"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analyse exploratoire du dataset\n",
    "Chargement des données,\n",
    "Aperçu des données,\n",
    "Informations sur le DataFrame,\n",
    "Statistiques descriptives,\n",
    "Vérification des valeurs manquantes,\n",
    "Compte des labels."
   ],
   "id": "98086ed76011ddf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Chargement des données\n",
    "df = pd.read_csv(\"dataset.csv\", sep='\\t', header=0, index_col=None)\n",
    "\n",
    "# Aperçu des données\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "# Vérification des valeurs manquantes\n",
    "print(df.isnull().sum())\n",
    "print(df['label'].value_counts())"
   ],
   "id": "a4788e2cd3f6b53d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prétraitement des données:\n",
    "Division des données en ensembles d'entraînement et de test,\n",
    "Vectorisation avec TF-IDF"
   ],
   "id": "cb5c04a60f0c72bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Séparation des données\n",
    "X = df['clean_text']  # Texte nettoyé\n",
    "y = df['label']       # Cible (ados/adult)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "8e50c935ef70ddc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Vectorisation du texte\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ],
   "id": "91627170d30fcaab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Choix des algorithmes\n",
    "Logistic Regression : Performant pour les tâches de classification binaire avec des données vectorisées.\n",
    "Random Forest : Gère les relations non linéaires et les données déséquilibrées."
   ],
   "id": "3034a1fdf1626d4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Entraînement des modèles\n",
   "id": "6eda0bfea627b47c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Entraînement\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Évaluation\n",
    "y_pred_lr = lr_model.predict(X_test_vectorized)\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))"
   ],
   "id": "2a46ee69d9a637f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Entraînement\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Évaluation\n",
    "y_pred_rf = rf_model.predict(X_test_vectorized)\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ],
   "id": "48869f41a5bb9297",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparaison des modèles\n",
    "Les résultats montrent une différence significative entre les deux modèles en termes de performances globales. Voici une analyse comparative basée sur les métriques obtenues :\n",
    "1. Performance globale (Accuracy)\n",
    "Logistic Regression : 88.04%\n",
    "Random Forest : 83.24%\n",
    "➡️ Le modèle Logistic Regression offre une meilleure précision globale, indiquant qu'il est plus performant pour classer correctement les données.\n",
    "2. Précision (Precision)\n",
    "Logistic Regression :\n",
    "Ados : 86%\n",
    "Adult : 90%\n",
    "Random Forest :\n",
    "Ados : 81%\n",
    "Adult : 85%\n",
    "➡️ La régression logistique est plus précise, en particulier pour la classe \"adult\". Cela signifie qu'elle génère moins de   faux positifs par rapport à Random Forest.\n",
    "3. Rappel (Recall)\n",
    "Logistic Regression :\n",
    "Ados : 88%\n",
    "Adult : 88%\n",
    "Random Forest :\n",
    "Ados : 82%\n",
    "Adult : 84%\n",
    "➡️ La régression logistique a un meilleur rappel pour les deux classes, ce qui indique qu'elle est plus efficace pour identifier les vrais positifs.\n",
    "4. Score F1\n",
    "Logistic Regression :\n",
    "Ados : 87%\n",
    "Adult : 89%\n",
    "Random Forest :\n",
    "Ados : 81%\n",
    "Adult : 85%\n",
    "➡️ La régression logistique a des scores F1 plus élevés, démontrant un bon équilibre entre la précision et le rappel.\n",
    "5. Interprétation et Scalabilité\n",
    "Logistic Regression :\n",
    "Plus simple et plus rapide à entraîner.\n",
    "Plus facilement interprétable grâce à ses coefficients.\n",
    "Random Forest :\n",
    "Plus complexe et plus lent, surtout avec un grand nombre d'estimateurs.\n",
    "Moins interprétable en raison de la nature des arbres de décision combinés.\n",
    "Conclusion :\n",
    "Le modèle Logistic Regression est plus performant que le Random Forest dans ce cas précis. Avec une précision, un rappel et un score F1 supérieurs, il est préférable pour la classification des textes en \"ados\" ou \"adult\".\n",
    "\n",
    "\n"
   ],
   "id": "f364e5089ec95b8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chargement du modèle et le vectorizer",
   "id": "200321c2b33fdfe1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "with open(\"final_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lr_model, f)  # Utilisez le modèle que vous souhaitez déployer (lr_model ou rf_model)\n",
    "\n",
    "# Sauvegarde du vectorizer\n",
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ],
   "id": "3f47725068507f72",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
